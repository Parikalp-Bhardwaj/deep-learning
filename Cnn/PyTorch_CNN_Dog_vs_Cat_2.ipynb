{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from torch.autograd import Variable\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'REBUILD_DATA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-20aaecc1c4cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Dogs:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdogsvcats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdogcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[0mREBUILD_DATA\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[0mdogsvcats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDogsVSCats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mdogsvcats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_training_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'REBUILD_DATA' is not defined"
     ]
    }
   ],
   "source": [
    "class DogsVSCats():\n",
    "    IMG_SIZE = 50\n",
    "    CATS = \"C:/Users/PARIKALP/AppData/Local/Programs/Python/Scripts/dog vs cat/dataset/test_set/cats/\"\n",
    "    DOGS=\"C:/Users/PARIKALP/AppData/Local/Programs/Python/Scripts/dog vs cat/dataset/test_set/dogs/\"\n",
    "    TESTING = \"C:/Users/PARIKALP/AppData/Local/Programs/Python/Scripts/dog vs cat/dataset/test_set\"\n",
    "    LABELS = {CATS: 0, DOGS: 1}\n",
    "    training_data = []\n",
    "\n",
    "    catcount = 0\n",
    "    dogcount = 0\n",
    "\n",
    "    def make_training_data(self):\n",
    "        for label in self.LABELS:\n",
    "            print(label)\n",
    "            for f in tqdm(os.listdir(label)):\n",
    "                if \"jpg\" in f:\n",
    "                    try:\n",
    "                        path = os.path.join(label, f)\n",
    "                        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "                        img = cv2.resize(img, (self.IMG_SIZE, self.IMG_SIZE))\n",
    "                        self.training_data.append([np.array(img), np.eye(2)[self.LABELS[label]]])  # do something like print(np.eye(2)[1]), just makes one_hot \n",
    "                        #print(np.eye(2)[self.LABELS[label]])\n",
    "\n",
    "                        if label == self.CATS:\n",
    "                            self.catcount += 1\n",
    "                        elif label == self.DOGS:\n",
    "                            self.dogcount += 1\n",
    "\n",
    "                    except Exception as e:\n",
    "                        pass\n",
    "                        #print(label, f, str(e))\n",
    "\n",
    "        np.random.shuffle(self.training_data)\n",
    "        np.save(\"training_data.npy\", self.training_data)\n",
    "        print('Cats:',dogsvcats.catcount)\n",
    "        print('Dogs:',dogsvcats.dogcount)\n",
    "\n",
    "if REBUILD_DATA:\n",
    "    dogsvcats = DogsVSCats()\n",
    "    dogsvcats.make_training_data()\n",
    "\n",
    "\n",
    "training_data = np.load(\"training_data.npy\", allow_pickle=True)\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/PARIKALP/AppData/Local/Programs/Python/Scripts/dog vs cat/dataset/test_set/cats/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [01:02<00:00, 15.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/PARIKALP/AppData/Local/Programs/Python/Scripts/dog vs cat/dataset/test_set/dogs/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:45<00:00, 22.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cats: 1000\n",
      "Dogs: 1000\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 50\n",
    "CATS = \"C:/Users/PARIKALP/AppData/Local/Programs/Python/Scripts/dog vs cat/dataset/test_set/cats/\"\n",
    "DOGS=\"C:/Users/PARIKALP/AppData/Local/Programs/Python/Scripts/dog vs cat/dataset/test_set/dogs/\"\n",
    "TESTING = \"C:/Users/PARIKALP/AppData/Local/Programs/Python/Scripts/dog vs cat/dataset/test_set\"\n",
    "LABELS = {CATS: 0, DOGS: 1}\n",
    "training_data = []\n",
    "catcount = 0\n",
    "dogcount = 0\n",
    "\n",
    "for label in LABELS:\n",
    "    print(label)\n",
    "    for f in tqdm(os.listdir(label)):\n",
    "        if \"jpg\" in f:\n",
    "            path = os.path.join(label, f)\n",
    "            img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "            img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
    "            training_data.append([np.array(img), np.eye(2)[LABELS[label]]])\n",
    "            \n",
    "            if label == CATS:\n",
    "                catcount += 1\n",
    "            elif label == DOGS:\n",
    "                dogcount += 1\n",
    "    \n",
    "    \n",
    "np.random.shuffle(training_data)\n",
    "np.save(\"training_data.npy\",training_data)\n",
    "print('Cats:',catcount)\n",
    "print('Dogs:',dogcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.Tensor([i[0] for i in training_data]).view(-1,50,50)\n",
    "X = X/255.0\n",
    "y = torch.Tensor([i[1] for i in training_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2000, 50, 50]), torch.Size([2000, 2]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "VAL_PCT = 1 # lets reserve 10% of our data for validation\n",
    "val_size = int(len(X)*VAL_PCT)\n",
    "print(val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = X[:-val_size]\n",
    "train_y = y[:-val_size]\n",
    "\n",
    "test_X = X[-val_size:]\n",
    "test_y = y[-val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 2000, 2000)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_X),len(train_y),len(test_X),len(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([0, 50, 50]),\n",
       " torch.Size([0, 2]),\n",
       " torch.Size([2000, 50, 50]),\n",
       " torch.Size([2000, 2]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape,train_y.shape,test_X.shape,test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() # just run the init of parent class (nn.Module)\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5) # input is 1 image, 32 output channels, 5x5 kernel / window\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5) # input is 32, bc the first layer output 32. Then we say the output will be 64 channels, 5x5 kernel / window\n",
    "        self.conv3 = nn.Conv2d(64, 128, 5)\n",
    "\n",
    "        x = torch.randn(50,50).view(-1,1,50,50)\n",
    "        self._to_linear = None\n",
    "        self.convs(x)\n",
    "\n",
    "        self.fc1 = nn.Linear(self._to_linear, 512) #flattening.\n",
    "        self.fc2 = nn.Linear(512, 2) # 512 in, 2 out bc we're doing 2 classes (dog vs cat).\n",
    "\n",
    "    def convs(self, x):\n",
    "        # max pooling over 2x2\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), (2, 2))\n",
    "\n",
    "        if self._to_linear is None:\n",
    "            self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1, self._to_linear)  # .view is reshape ... this flattens X before \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x) # bc this is our output layer. No activation here.\n",
    "        return F.softmax(x, dim=1)\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 100\n",
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for i in tqdm(range(0, len(train_X), BATCH_SIZE)): # from 0, to the len of x, stepping BATCH_SIZE at a time. [:50] ..for now just to dev\n",
    "        #print(f\"{i}:{i+BATCH_SIZE}\")\n",
    "        batch_X = train_X[i:i+BATCH_SIZE].view(-1, 1, 50, 50)\n",
    "        batch_y = train_y[i:i+BATCH_SIZE]\n",
    "\n",
    "        net.zero_grad()\n",
    "\n",
    "        outputs = net(batch_X)\n",
    "        loss = loss_function(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()    # Does the update\n",
    "\n",
    "        print(f\"Epoch: {epoch}. Loss: {loss.data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.0\n",
      "Accuracy:  0.5\n",
      "Accuracy:  0.667\n",
      "Accuracy:  0.5\n",
      "Accuracy:  0.4\n",
      "Accuracy:  0.333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▉                                                                             | 6/100 [00:00<00:01, 49.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.286\n",
      "Accuracy:  0.25\n",
      "Accuracy:  0.333\n",
      "Accuracy:  0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████████                                                                         | 10/100 [00:00<00:02, 44.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.455\n",
      "Accuracy:  0.417\n",
      "Accuracy:  0.462\n",
      "Accuracy:  0.429\n",
      "Accuracy:  0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████▏                                                                    | 15/100 [00:00<00:01, 44.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.375\n",
      "Accuracy:  0.412\n",
      "Accuracy:  0.389\n",
      "Accuracy:  0.368\n",
      "Accuracy:  0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▏                                                                | 20/100 [00:00<00:01, 44.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.429\n",
      "Accuracy:  0.409\n",
      "Accuracy:  0.435\n",
      "Accuracy:  0.458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|███████████████████▍                                                             | 24/100 [00:00<00:02, 35.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.44\n",
      "Accuracy:  0.462\n",
      "Accuracy:  0.444\n",
      "Accuracy:  0.464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██████████████████████▋                                                          | 28/100 [00:00<00:02, 30.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.448\n",
      "Accuracy:  0.433\n",
      "Accuracy:  0.419\n",
      "Accuracy:  0.438\n",
      "Accuracy:  0.455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|██████████████████████████▋                                                      | 33/100 [00:00<00:02, 33.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.471\n",
      "Accuracy:  0.457\n",
      "Accuracy:  0.444\n",
      "Accuracy:  0.459\n",
      "Accuracy:  0.447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|██████████████████████████████▊                                                  | 38/100 [00:01<00:01, 35.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.436\n",
      "Accuracy:  0.425\n",
      "Accuracy:  0.439\n",
      "Accuracy:  0.452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|██████████████████████████████████                                               | 42/100 [00:01<00:01, 33.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.442\n",
      "Accuracy:  0.432\n",
      "Accuracy:  0.422\n",
      "Accuracy:  0.413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|█████████████████████████████████████▎                                           | 46/100 [00:01<00:01, 34.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.426\n",
      "Accuracy:  0.417\n",
      "Accuracy:  0.408\n",
      "Accuracy:  0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████████████████████████▌                                        | 50/100 [00:01<00:01, 35.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.412\n",
      "Accuracy:  0.404\n",
      "Accuracy:  0.396\n",
      "Accuracy:  0.407\n",
      "Accuracy:  0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|████████████████████████████████████████████▌                                    | 55/100 [00:01<00:01, 37.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.393\n",
      "Accuracy:  0.404\n",
      "Accuracy:  0.414\n",
      "Accuracy:  0.407\n",
      "Accuracy:  0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|████████████████████████████████████████████████▌                                | 60/100 [00:01<00:00, 40.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.393\n",
      "Accuracy:  0.403\n",
      "Accuracy:  0.413\n",
      "Accuracy:  0.406\n",
      "Accuracy:  0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|████████████████████████████████████████████████████▋                            | 65/100 [00:01<00:00, 41.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.409\n",
      "Accuracy:  0.403\n",
      "Accuracy:  0.412\n",
      "Accuracy:  0.406\n",
      "Accuracy:  0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████████████████████████████████████████████████▋                        | 70/100 [00:02<00:01, 28.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.408\n",
      "Accuracy:  0.417\n",
      "Accuracy:  0.411\n",
      "Accuracy:  0.405\n",
      "Accuracy:  0.413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|████████████████████████████████████████████████████████████▊                    | 75/100 [00:02<00:00, 31.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.408\n",
      "Accuracy:  0.403\n",
      "Accuracy:  0.41\n",
      "Accuracy:  0.405\n",
      "Accuracy:  0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████████████████████████████████████████▊                | 80/100 [00:02<00:00, 35.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.407\n",
      "Accuracy:  0.402\n",
      "Accuracy:  0.41\n",
      "Accuracy:  0.405\n",
      "Accuracy:  0.4\n",
      "Accuracy:  0.395\n",
      "Accuracy:  0.402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|██████████████████████████████████████████████████████████████████████▍          | 87/100 [00:02<00:00, 40.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.398\n",
      "Accuracy:  0.404\n",
      "Accuracy:  0.411\n",
      "Accuracy:  0.407\n",
      "Accuracy:  0.402\n",
      "Accuracy:  0.409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|███████████████████████████████████████████████████████████████████████████▎     | 93/100 [00:02<00:00, 44.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.404\n",
      "Accuracy:  0.411\n",
      "Accuracy:  0.406\n",
      "Accuracy:  0.402\n",
      "Accuracy:  0.398\n",
      "Accuracy:  0.394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|████████████████████████████████████████████████████████████████████████████████▏| 99/100 [00:02<00:00, 47.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:02<00:00, 38.79it/s]\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(100)):\n",
    "        real_class = torch.argmax(test_y[i])\n",
    "        net_out = net(test_X[i].view(-1, 1, 50, 50))[0]  # returns a list, \n",
    "        predicted_class = torch.argmax(net_out)\n",
    "\n",
    "        if predicted_class == real_class:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "        print(\"Accuracy: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS=10\n",
    "for epoch in range(EPOCHS):\n",
    "    for i in range(0, len(train_X), BATCH_SIZE): # from 0, to the len of x, stepping BATCH_SIZE at a time. [:50] ..for now just to dev\n",
    "        #print(f\"{i}:{i+BATCH_SIZE}\")\n",
    "        image= train_X[i:i+BATCH_SIZE].view(-1, 1, 50, 50)\n",
    "        label = train_y[i:i+BATCH_SIZE]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output=model(image)\n",
    "        \n",
    "        loss=criterion(output,label)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        iter+=1\n",
    "        if iter%500==0:\n",
    "            correct=0\n",
    "            \n",
    "            total=0\n",
    "            \n",
    "            for image,label in test_loader:\n",
    "            \n",
    "                image=Variable(image)\n",
    "            \n",
    "                output=model(image)\n",
    "            \n",
    "                _,prediction=torch.max(output.data,1)\n",
    "            \n",
    "                total+=label.size(0)\n",
    "            \n",
    "                correct+= (prediction == label).sum()\n",
    "            \n",
    "                accuracy=100*correct/total\n",
    "        \n",
    "            print(\"Iteraion : {} , Loss : {} , Accuracy : {}\".format(iter,loss.data,accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=\"./dog vs cat/dataset/test_set/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfrom_data=transforms.Compose([transforms.Compose((32,32)),transforms.ToTensor(),\n",
    "                                  transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog=glob.glob(data+\"dogs/*.jpg\")\n",
    "cat=glob.glob(data+\"cats/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=dog+cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dataset=torchvision.datasets.ImageFolder(root=data,transform=transfrom_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Sum of input lengths does not equal the length of the input dataset!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-8a1407740113>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m600\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\parikalp\\appdata\\local\\programs\\python\\lib\\site-packages\\torch\\utils\\data\\dataset.py\u001b[0m in \u001b[0;36mrandom_split\u001b[1;34m(dataset, lengths)\u001b[0m\n\u001b[0;32m    269\u001b[0m     \"\"\"\n\u001b[0;32m    270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Sum of input lengths does not equal the length of the input dataset!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m     \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandperm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Sum of input lengths does not equal the length of the input dataset!"
     ]
    }
   ],
   "source": [
    "train_set,test_set=torch.utils.data.random_split(img_dataset,(2000,600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.86349001931745"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6000/1553"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.389830508474576"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2000/590"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
